import astropy.units as u
import astropy.constants as c
from astropy.coordinates import SkyCoord
from astropy.time import Time
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import glob
from astropy.io import fits
from itertools import combinations
import pickle
from astropy.cosmology import WMAP9 as cosmo
plt.rcParams['figure.figsize'] = (10, 10)
plt.rc('axes', labelsize=14)
plt.rc('axes', labelweight='bold')
plt.rc('axes', titlesize=16)
plt.rc('axes', titleweight='bold')
plt.rc('font', family='sans-serif')
def get_color_table(dfi):
    """
    Generates a DataFrame of the colors that can be created with the input DataFrame
    
    Parameters
    ---
    dfi: pandas DataFrame, 
        generated by load_photometry function
    
    Returns
    ---
    df: pandas DataFrame
        contains all possible color combinations and their errors
    
    """
    #Grab the filters from the DataFrame
    filters = dfi.keys()[4:16]
    #Initialize an empty DataFrame
    df = pd.DataFrame({})
    #Loop through all possible combinations of 2 filters
    for i in combinations(filters, 2):
        #Check if either of the elements associated with the filter are NaN
        strng0 = float(i[0].split('F')[1])
        strng1 = float(i[1].split('F')[1])
        if strng0<strng1:
            if np.nansum(dfi[f'{i[0]}'])!= 0 and np.nansum(dfi[f'{i[1]}']) !=0:
                #If neither are NaN, add the color to the DataFrame
                f0 = dfi[f'{i[0]}']
                f1 = dfi[f'{i[1]}']
                df[f'{i[0]} - {i[1]}'] = -1*2.5*np.log10((f0)/(f1))
                f0_err = dfi[f'{i[0]}_ERROR']
                f1_err =  dfi[f'{i[1]}_ERROR']
                error = np.sqrt(((((-2.5)/(np.log(10)))*(1/f0))**2)*((f0_err)**2) + ((((2.5)/(np.log(10)))*(1/f1))**2)*((f1_err)**2) )
                df[f'{i[0]} - {i[1]}_ERROR'] = error
            else:
                #If either is NaN, let the color value be NaN
                df[f'{i[0]} - {i[1]}'] = np.nan
                df[f'{i[0]} - {i[1]}_ERROR'] = np.nan
    df['Object'] = dfi['Object']
    return df
def load_photometry(path, rainbow_path):
    """
    Initializes a Pandas DataFrame with photometry information
    
    Parameters
    ---
    path: string 
        absolute path to a *photom.fits photometry file
        
    rainbow_path: string
        absolute path to rainbows data file
        
    Returns
    ---
    df: pandas DataFrame
        DataFrame containing photometric information for each source. Each row indicates one source. The
        column names indicate the following:
        
        RA: Right Ascension of source in decimal degrees 
        
        DEC: Declination of source in decimal degrees 
        
        Region: either a 1 or 2 indicating if the source appears in the region of lesser Right Ascension (2)
                or the region of greater Right Ascension (1)
        
        Stellarity: A parameter (between 0.0 and 1.0), generated by a neural network, that seeks to 
                    characterize how stellar an observed astronomical object is.
                    https://en.wiktionary.org/wiki/stellarity
        
        F115: Source flux in 115 filter, units of nJy 
        
        F150: Source flux in 150 filter, units of nJy
        
        F200: Source flux in 200 filter, units of nJy
        
        F277: Source flux in 277 filter, units of nJy
        
        F356: Source flux in 356 filter, units of nJy
        
        F410: Source flux in 410 filter, units of nJy 
        
        F444: Source flux in 444 filter, units of nJy 
        
        F606 : Source flux in 60.6 filter, units of nJy (Hubble Fitler)
        
        F814 : Source flux in 81.4 filter, units of nJy (Hubble Filter)
        
        F105: Source flux in 105 filter, units of nJy (Hubble Filter)
        
        F125: Source flux in 125 filter, units of nJy 
        
        F140: Source flux in 140 filter, units of nJy
        
        F160: Source flux in 160 filter, units of nJy
        
        F115_ERROR: Error in 115 filter flux, units of nJy 
        
        F150_ERROR: Error in 150 filter flux, units of nJy
        
        F200_ERROR: Error in 200 filter flux, units of nJy
        
        F277_ERROR: Error in 277 filter flux, units of nJy 
        
        F356_ERROR: Error in 356 filter flux, units of nJy
        
        F410_ERROR: Error in 410 filter flux, units of nJy 
        
        F444_ERROR: Error in 444 filter flux, units of nJy
        
        F606_ERROR: Error in 60.6 filter flux, units of nJy
        
        F814_ERROR: Error in 81.4 filter flux, units of nJy 
        
        F105_ERROR: Error in 105 filter flux, units of nJy
        
        F125_ERROR: Error in 125 filter flux, units of nJy 
        
        F140_ERROR: Error in 140 filter flux, units of nJy 
        
        F160_ERROR: Error in 160 filter flux, units of nJy 
        
        SPECTRAL_RED_SHIFT: spectral redshift, value of -1 indicates no recorded redshift
        
        STELLAR_MASS: stellar mass, source mass in units of solar masses
            https://en.wikipedia.org/wiki/Stellar_mass
        
        STELLAR_MASS_ERR: error in stellar mass
        
        PHOTOM_RED_SHIFT: photometric redshift, value of -1 indicates no recorded redshift 
        
        Object: string used to identify object. These have form:
            nircamA-B where A indicates the pointing and B is the source number.
            
        X: x pixel coordinate of object
        
        Y: y pixel coordinate of object
    
    """
    rainbow = pd.read_table(rainbow_path)
    undet = []
    #Opening the file
    hdu1 = fits.open(path)
    #Defining empty lists to store data
    filters= []
    flags = []
    #Looping through each of the keywords in the .fits file
    for key in hdu1[1].columns:
        #If the keyword starts with an F and has type D,
        if key.name[0] == 'F' and key.format == 'D':
            #Check that the filter contains data and not just NaN values
            #This is the first instance of byte swapping in this code. This is absolutley necessary when
            #switching from a FITS input to a pandas DataFrame due to byte order support with Pandas.
            #If this byte swapping is absent, an error for big endian buffers on a little endian 
            #compiler will raise.
            if np.nansum(hdu1[1].data[f'{key.name}'].byteswap().newbyteorder()) !=0:
                #Add the filter to the filter list
                filters.append(key.name)
    #Remove the FWHM keyword from the end of the list
    filters.remove(filters[-1])
    #Loop through the x positions of the data points
    for x in hdu1[1].data['X'].byteswap().newbyteorder():
    #Check if the position is in the right of the frame
        if x > 5000:
            #Flag this as region 2
            flags.append(2)
        #Flag other points as region 1
        else:
            flags.append(1)
    #Initalize a pandas Data Frame with the RA and DEC positional coordinates
    df = pd.DataFrame({'RA': hdu1[1].data['RA'].byteswap().newbyteorder(), 
                       'DEC': hdu1[1].data['DEC'].byteswap().newbyteorder()})
    #Add the region flags to the DataFrame
    df['Region'] = flags
    df['Stellarity'] = hdu1[1].data['STELLARITY'].byteswap().newbyteorder()
    #Add each filter to the DataFrame
    for f in filters:
        df[f'{f}'] = hdu1[1].data[f'{f}'].byteswap().newbyteorder()
    for f in filters:
        df[f'{f}_ERROR'] = hdu1[1].data[f'D{f}'].byteswap().newbyteorder()
    #Match the sources to the rainbows data, use the index array idk to order the rainbows 
    #data so that it can be added to the DataFrame in the correct order
    c = SkyCoord(ra=hdu1[1].data['RA']*u.degree, dec=hdu1[1].data['DEC']*u.degree)
    catalog = SkyCoord(ra=rainbow['ALPHA_GR_DEC']*u.degree, dec=rainbow['DELTA_GR_DEC']*u.degree)
    idx, d2d, d3d = c.match_to_catalog_sky(catalog)
    #Adding the data columns from Rainbows
    df['SPECTRAL_RED_SHIFT'] = np.array(rainbow['specz_redshift'][idx])
    df['STELLAR_MASS'] = np.array(rainbow['specz_stellar_mass'][idx])
    df['STELLAR_MASS_ERR'] = np.array(rainbow['specz_stellar_mass_err'][idx])
    df['PHOTOM_RED_SHIFT'] = np.array(rainbow['photo_redshift_bis'][idx])
    df['Object'] = np.array(rainbow['object'][idx])
    #Adding the pixel coordinates
    df['X'] = hdu1[1].data['X'].byteswap().newbyteorder()
    df['Y'] = hdu1[1].data['Y'].byteswap().newbyteorder()
    df['SFR'] = np.array(rainbow['SFR_TOT_final'][idx])
    #Return the DataFrame
    return df
def john_plot(rs, df, source = None):
    """
    Plots expected prominant emission lines as they varry through redshifts and indicates where a specified
    redshift will land on this plot.
    
    Parameters
    ---
    
    rs: float between 0 and 10
        value of object's redshift
        
    df: pandas DataFrame
        DataFrame generated by load_photometry function
        
    source: string, optional
        the name of the source given by the Object column of the DataFrame. If this is not specified,
        a plot will be generated with no redshift lines.
    
    
    Returns
    ---
    
    figure: plot of emission lines with redshift indicated
    
    """
    #Defining emission line constants
    ha = 6563
    nii = 6584
    o3 = 5007
    o3_2 = 4959
    hb = 4861
    hd = 4101
    ne3 = 3870
    o2 = 3727
    ciii = 1909
    civ = 1550
    lya = 1216
    paa = 18750
    pab = 12820
    #Specifying figure size
    plt.rcParams['figure.figsize'] = (20, 10)
    # Grabbing filters for source from the DataFrame
    fs = []
    fs_strings = []
    a=df.index[0]
    c=0
    try:
        fs = []
        fs_strings = []
        for key in df.loc[a][4:17].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start=4
        stop=17
        stop2 = 30
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)
    except:
        fs = []
        fs_strings = []
        c+=1
        for key in df.loc[a][4:16].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start = 4
        stop = 16
        stop2=28
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)
    #Adding the filters to the plot labels
    plt.xticks(np.array(f_final))
    # Plotting spans for each of the filters
    plt.axvspan(388, 498.6, label= 'F444', color = 'r', alpha = .25)
    plt.axvspan(386.4, 430.1, label= 'F410', alpha = 0.25, color = 'orange')
    plt.axvspan(314, 398, label= 'F356', color = 'y', alpha = .25)
    plt.axvspan(241.6, 312.7, label= 'F277', color = 'g', alpha = .25)
    plt.axvspan(175.5, 222.6, label= 'F200', color = 'cyan', alpha = .25)
    plt.axvspan(133.1, 166.8, label= 'F150', color = 'blue', alpha = .25)
    plt.axvspan(101.3, 128.2, label= 'F115', color = 'purple', alpha = .25)
    #Making a range for the emission line calculations
    zarr = np.arange(0,100)
    #Ploting H alpha and NII lines
    plt.plot(1e-4*ha*(1+zarr)*1e2,zarr, c= 'red')
    plt.plot(1e-4*nii*(1+zarr)*1e2,zarr, c= 'r', label = r'H$\alpha$ + [NII]')
    #Plotting H betta and OIII lines
    plt.plot(1e-4*o3*(1+zarr)*1e2,zarr, color='darkgreen')
    plt.plot(1e-4*o3_2*(1+zarr)*1e2,zarr, color='darkgreen')
    plt.plot(1e-4*hb*(1+zarr)*1e2,zarr, color='darkgreen', label = r'H$\beta$+[OIII]')
    #Plotting OII and NEIII lines
    plt.plot(1e-4*o2*(1+zarr)*1e2,zarr, color='blue')
    plt.plot(1e-4*ne3*(1+zarr)*1e2,zarr, color='blue', label = '[OII]+[NeIII]')
    #Plotting Pa lines
    plt.plot(1e-4*paa*(1+zarr)*1e2,zarr, color='brown', label = r'Pa$\alpha$')
    #Plotting Pb lines
    plt.plot(1e-4*pab*(1+zarr)*1e2,zarr, color='brown',label = r'Pa$\beta$')
    #Plotting Lya lines
    plt.plot(1e-4*lya*(1+zarr)*1e2,zarr, color='red', label = r'Ly$\alpha$')
    #Plotting CIV lines
    plt.plot(1e-4*civ*(1+zarr)*1e2,zarr, color='red', label = r'CIV')
    #Plottinh CIII lines
    plt.plot(1e-4*ciii*(1+zarr)*1e2,zarr, color='red', label = r'CIII')
    #Adding text to all emission lines
    plt.text(400, 5.25, r'H$\alpha$ + [NII]', rotation = 25, c = 'r', zorder = 1)
    plt.text(400, 7.5, r'H$\beta$+[OIII]', rotation = 25, c = 'darkgreen',zorder = 1)
    plt.text(277, 7, '[OII]+[NeIII]', rotation = 25, c = 'b', zorder = 1)
    plt.text(420, 2.5, r'Pa$\alpha$', rotation = 15, c = 'brown',zorder = 1)
    plt.text(420, 1.5, r'Pa$\beta$', rotation = 15, c = 'brown', zorder = 1)
    plt.text(115, 9.25, r'Ly$\alpha$', rotation = 55, c = 'red', zorder = 1)
    plt.text(115, 7.1, r'CIV', rotation = 45, c = 'red', zorder = 1)
    plt.text(105, 4.85, r'CIII', rotation = 45, c = 'red', zorder = 1)
    #If a source is not specified, simply plot the emission lines. If it is specified add it to the plot
    if source is None:
        plt.title('Lines of Interest')
    else:
        #Adding the redhsift line to the plot 
        plt.axhline(rs, color = 'k', lw = 10)
        plt.text(120, rs+.25, f'Spectral Redshift = {rs}', rotation = 0, fontweight = 'bold', zorder = 10)
        plt.title(f'Lines of Interest {source}')
    plt.ylabel('Redshift')
    plt.xlabel('Filter')
    #Rotate the ticks, set fixed axes limits
    plt.xticks(rotation = 45)
    plt.tick_params('y', length=10, width=1, which='minor')
    plt.ylim(0,10)
    plt.xlim(100,500);
def investigate_source(source,df, df_col, pointing, save_SED = False):
    """
    Produces 2 plots. One plot indicates the relevant emission lines for a particular redshift. The other
    is an SED plot of a given source.
    
    Paramteres
    ---
    source: string,
            identifier from Object column of df
            
    df: pandas DataFrame
        DataFrame from load_photometry function
        
    df_col: pandas DataFrame
        DataFrame from get_color_table function
        
    poiting: integer
        indication of the pointing for this source
        
    save_SED: boolean, optional
            default set to false, set to true to save figures generated
        
    Returns
    ---
    
    figure1:
    
    figure2:
    """
    dc = df_col
    num = pointing
    a = df.index[0]
    #Get the DataFrame for only this source, grab the redshift
    d = df.loc[df['Object'] == source]
    rs = np.array(d['SPECTRAL_RED_SHIFT'])[0]
    #Set figure size
    plt.rcParams['figure.figsize'] = (10, 5)
    #Call the emission line plot function for this source's redshift
    john_plot(rs, df, source)
    #Create a boolean mask for data points where the 356,410, and 444 filters have values greater than
    #3 times their errors
    #msk = (d['F410'] > 3*d['F410_ERROR']) & (d['F444'] > 3*d['F444_ERROR']) & (d['F356'] > 3*d['F356_ERROR'])
    # Set figure size for second plot and initiate a figure
    plt.rcParams['figure.figsize'] = (10, 5)
    plt.figure()
    #Grab the filters from the DataFrame
    #ADJUST THIS SO FILTERS CAN VARY
    fs = []
    fs_strings = []
    filter_val = []
    error_strings = []
    for key in d.keys()[4:16]:
        fs.append(float(key.split('F')[1]))
        fs_strings.append(key)
    for key in d.keys()[17:29]:
        error_strings.append(key)
    f_final = []
    for f in fs:
        if f>600:
            f_final.append(f*.1)
        else:
            f_final.append(f)
    #Grab filter values, mask the data so that it only includes data point where flux is more than 3 times the 
    #error, the flux is nonzero, and the error is nonzero.
    filters = d[fs_strings]
    errors = d[error_strings]
    mask = (filters.values > 3*errors.values) & (filters.values >=0) & (errors.values >=0)
    #Plot the SED plot and include error bars
    plt.errorbar(np.array(f_final)[mask[0]], filters.values[mask], marker = '.', yerr = errors.values[mask], ls = 'none')
    #Add filters to x axis, rotate them 45 degrees
    plt.xticks(np.array(f_final)[mask[0]])
    plt.xticks(rotation = 45)
    #Add 277,356,410, and 444 filters to plot
    plt.axvspan(314, 398, label= 'F356', color = 'y', alpha = .25)
    plt.axvspan(386.4, 430.1, label= 'F410', alpha = 0.25, color = 'orange')
    plt.axvspan(388, 498.6, label= 'F444', color = 'r', alpha = .25)
    plt.axvspan(241.6, 312.7, label= 'F277', color = 'g', alpha = .25)
    #Add title and axes lable
    plt.ylabel('Flux (nJy)')
    obj=np.array(d['Object'])[0]
    rs = np.array(d['PHOTOM_RED_SHIFT'])[0]
    rs_spec = np.array(d['SPECTRAL_RED_SHIFT'])[0]
    plt.title(f'Flux across filters for {obj} \n photometric redshift = {rs}')
    plt.legend()
    #Save and display the figure
    plt.xlim(100,500)
    if save_SED == True:
        plt.savefig(f'/home/kelcey/starting_plots/{obj}.png')
    plt.figure();
def plot_sources(sources, df, df_col, num):
    """
    Plots overlapping SED plots for a set of specified sources and their position on a color-color diagram
    
    Parameters
    ---
    sources: string or list of strings
        identifiers for objects as specified in the Objects column of df
        
    df: pandas DataFrame
        DataFrame from load_photometry function
        
    df_col: pandas DataFrame
        DataFrame from get_color_table function
        
    num: integer
        integer identifier of pointing number
        
    Returns
    ---
    figure1: color-color plot with indicated sources specified with the same color they
        are indicated with on the SED plot
    
    figure 2: matplotlib figure
        overlaid SED plots for the specified sources
    
    """
    # Set figure size
    plt.rcParams['figure.figsize'] = (20, 10)
    #Grab filters from DataFrame
    fs = []
    fs_strings = []
    a=df.index[0]
    c=0
    try:
        fs = []
        fs_strings = []
        for key in df.loc[a][4:17].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start=4
        stop=17
        stop2 = 30
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)
    except:
        fs = []
        fs_strings = []
        c+=1
        for key in df.loc[a][4:16].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start = 4
        stop = 16
        stop2=28
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)
    #Create a colormap 
    colormap = plt.cm.gist_ncar
    colors = [colormap(i) for i in np.linspace(0, 1,len(sources)+2)][1:-1]
    #Create an SED for each of the sources
    n=0
    for obj in sources:
        #Increase the iteration tracker, grab the DataFrame for just this object
        n+=1
        mk = np.array(df['Object']) == np.array(obj)
        a = df[mk]
        #Get the redshift and filters
        rs = a['PHOTOM_RED_SHIFT']
        filters = np.array(a.keys()[start:stop].values)
        filter_er = np.array(a.keys()[stop:stop2].values)
        #Mask the data so all filter values are greater than 3 times their error
        mask = ((a[filters].values[0] > (3*a[filter_er].values[0]))) & (a[filter_er].values[0]>0)
        
        #(filters.values > 3*errors.values) & (filters.values >=0) & (errors.values >=0)
        #Sort the data so the SED plot connects from left to right, regardless of filter input order
        z = sorted(zip(np.array(f_final)[mask],a[filters].values[0][mask]))
        x=[i[0] for i in z]
        y=[i[1] for i in z]
        plt.errorbar(x,y,a[filter_er].values[0][mask], #label = f'Redshift = {rs.values[0]}, {obj}',
                    color = colors[n-1])
        #Add the x ticks
        plt.xticks(np.array(f_final)[mask])
    #Add 277, 356, 410, and 444 filters
    plt.axvspan(314, 398, label= 'F356', color = 'y', alpha = .25)
    plt.axvspan(386.4, 430.1, label= 'F410', alpha = 0.25, color = 'orange')
    plt.axvspan(388, 498.6, label= 'F444', color = 'r', alpha = .25)
    plt.axvspan(241.6, 312.7, label= 'F277', color = 'g', alpha = .25)
    #Add titles and labels
    plt.title(f'Sources of Interest Nircam {num}')
    plt.ylabel('Flux (nJy)')
    #plt.yscale("log")
    plt.xlabel('Filter')
    plt.xticks(rotation = 45)
    #plt.legend()
    plt.tick_params('y', length=20, width=2, which='major')
    plt.tick_params('y', length=10, width=1, which='minor')
    plt.legend(loc='upper left');


    #Begin making the second figure
    a = 0
    plt.rcParams['figure.figsize'] = (10, 10)
    plt.figure()
    #Create two masks for the data in the color-color plot to specify filter value > 3 times error and position
    # in color-color plot
    msk = (df['F410'] > 3*df['F410_ERROR']) & (df['F444'] > 3*df['F444_ERROR']) & (df['F356'] > 3*df['F356_ERROR'])
    msk3 =  ((df_col['F356 - F410'][msk]>-1)  & (df_col['F410 - F444'][msk]<-.75))
    plt.scatter(df_col['F356 - F410'][msk], df_col['F410 - F444'][msk], s = 1, label = f'Pointing {num}', color = 'k')
    n = 0
    #Plot each sources with the correct color, indicated by a star
    for o in sources:
        n+=1
        data = g = df.loc[df['Object'] == o]
        ind = data.index
        plt.scatter(df_col.loc[ind]['F356 - F410'], df_col.loc[ind]['F410 - F444'], color = colors[n-1], marker = '*',
                   s = 100)
    #Add axes and titles
    plt.xlim(-6,6)
    plt.ylim(-6,6)
    plt.ylabel('F410 - F444')
    plt.xlabel('F356 - F410')
    plt.title(f'Nircam {num}');
def preliminary_search(d, dc, num, uppermin, uppermax, lowermin, lowermax):
    """
    Generates a color-color plot specifying position of relavent sources and plots their SED plots
    
    Parameters
    ---
        
    d: pandas DataFrame
        DataFrame from load_photometry function
        
    dc: pandas DataFrame
        DataFrame from get_color_table function
        
    uppermin: float
        minimum value for upper left corner
    
    uppermax: float
        maximum value for upper min corner
        
    lowermin: float
        minimum value fot lower right corner
        
    lowermax: float
        maximum value for lower right corner
        
    Returns:
    ---
    figure 1: color-color plot of all sources, plotted sources indicated by black xs
    
    all other figures: SED plots from investigate_source function
    
    """
    #Set figure size
    a = 0
    plt.rcParams['figure.figsize'] = (10, 10)
    #Create first data mask to only grab points where 356, 410, and 444 allhave values > 3 times their errors
    msk = (d['F410'] > 3*d['F410_ERROR']) & (d['F444'] > 3*d['F444_ERROR']) & (d['F356'] > 3*d['F356_ERROR'])
    #Create two additional masks to grab corners of color-color plot indicated by input bounds
    msk2 = ((dc['F356 - F410'][msk]<uppermin)  & (dc['F410 - F444'][msk]>uppermax))
    msk3 =  ((dc['F356 - F410'][msk]>lowermin)  & (dc['F410 - F444'][msk]<lowermax))
    #Plot a color-color plot of all the data points meeting the minimum error values
    plt.scatter(dc['F356 - F410'][msk], dc['F410 - F444'][msk], s = 10, label = f'Pointing {num}')
    plt.scatter(dc['F356 - F410'][msk][msk2], dc['F410 - F444'][msk][msk2], s = 50, label = f'Pointing {num}',
               marker = 'x', c = 'k');
    #Plot all the sources that meet minimum error values and are included in the indicated bounds
    plt.scatter(dc['F356 - F410'][msk][msk3], dc['F410 - F444'][msk][msk3], s = 50, label = f'Pointing {num}',
               marker = 'x', c = 'k');
    #Add axes and labels
    plt.ylabel('F410 - F444')
    plt.xlabel('F356 - F410')
    plt.xlim(-3.5,3.5)
    plt.ylim(-6,6)
    plt.title(f'Pointing {num}')
    #Create next figure
    plt.rcParams['figure.figsize'] = (20, 10)
    plt.figure()
    #Get filters from DataFrame
    fs = []
    fs_strings = []
    a=0
    plt.rcParams['figure.figsize'] = (20, 10)
    c=0
    try:
        fs = []
        fs_strings = []
        for key in df.loc[a][4:17].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start=4
        stop=17
        stop2 = 30
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)
    except:
        fs = []
        fs_strings = []
        c+=1
        for key in df.loc[a][4:16].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start = 4
        stop = 16
        stop2=28
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)   
    f_final = []
    for f in fs:
        if f>600:
            f_final.append(f*.1)
        else:
            f_final.append(f)
    #Generate SED plots for sources in upper-left corner
    for ind in d[msk][msk2].index:
        source = d[msk][msk2].loc[ind]['Object']
        investigate_source(source,d, dc, num)
    #Generate SED plots for sources in lower-right corner
    for ind in d[msk][msk3].index:
        source = d[msk][msk3].loc[ind]['Object']
        investigate_source(source,d, dc, num)
def cut_sides(df, best_df, num):
    """
    Takes a DataFrame of sources and compares it to a larger DataFrame. Sources either near the edge of the 
    detected sources or within an arcsecond of a bright source are thrown out
    
    Parameters
    ---
    df: pandas DataFrame
        DataFrame from load_photometry function
        
    best_df: pandas DataFrame
        a cut version of df, only including the sources of interest
    
    num: integer,
        integer pointing number
    
    Reutrns
    ---
    figure: matplotlib figure
        plot of all data in the pointing, indicating which 
            
    cut_data: pandas DataFrame
        the input DataFrame, only including sources that passed cuts
    
    """
    #Identify two seperate regions
    plt.rcParams['figure.figsize'] = (10, 10)
    plt.figure()
    db1 = best_df
    left = df[df['Region']==1]
    right = df[df['Region']==2]
    #Find the edges of the regions, draw a cutoff around the 100 pixel coordinates around the edge
    mn_x = np.min(df['X'])+100
    lmax_x = np.max(left['X'])-100
    rmin_x = np.min(right['X'])+100
    mx_x = np.max(df['X'])-100
    mn_y = np.min(df['Y'])+100
    lmax_y = np.max(left['Y'])-100
    rmin_y = np.min(right['Y'])+100
    mx_y = np.max(df['Y'])-100
    #Create lists to store the relavent sources
    post_cut = []
    too_close = []
    #For each of the sources in the smaller DataFrame
    for i in db1.index:
        #Get the DataFrame only includin that source
        dfsource = db1.loc[i]
        #Check if it is in the leftmost region, if it lies inside the cut region, keep the source
        if dfsource['Region'] == 1:
            if dfsource['X']>mn_x:
                if dfsource['X']<lmax_x:
                    if dfsource['Y']>mn_y:
                        if dfsource['Y']<lmax_y:
                            post_cut.append(i)
        #If the source is in the rightmost region, check if it passes the cuts for that region
        if dfsource['Region'] == 2:  
            if dfsource['X']>rmin_x:
                if dfsource['X']<mx_x:
                    if dfsource['Y']>rmin_y:
                        if dfsource['Y']<mx_y:
                            post_cut.append(i)
    #Plot all the sources that were observed in the region
    plt.scatter(df['RA'], df['DEC'], label = 'Data')
    #Add a gold star for sources that were eliminated due to proximity to edge
    plt.scatter(db1['RA'], db1['DEC'], c = 'gold', marker = '*', s = 200, zorder = 1, 
                label = 'Tossed - close to edge')
    #Look only at the sources that passed the edge proximity check
    for ind in db1.loc[post_cut].index:
        dfsource = db1.loc[ind]
        ra = df.loc[ind]['RA']
        dec = df.loc[ind]['DEC']
        #Create a data frame that includes all sources but the one currntly being looped over
        l = df.drop(ind)
        ra2 = l['RA']
        dec2= l['DEC']
        #Look at all sources within one arcsecond of the source being looped over
        leftovers =l[SkyCoord(ra2*u.deg, dec2*u.deg).separation(SkyCoord(ra*u.deg,dec*u.deg))<1*u.arcsec]
        #If any sources are found to be within one arcsecond
        if len(leftovers)>0:
            #Grab the filters
            try:
                a=ind
                fs = []
                fs_strings = []
                for key in df.loc[a][4:17].keys():
                    fs.append(float(key.split('F')[1]))
                    fs_strings.append(key)
                start=4
                stop=17
                stop2 = 30
                f_final = []
                for f in fs:
                    if f>600:
                        f_final.append(f*.1)
                    else:
                        f_final.append(f)
            except:
                a=ind
                fs = []
                fs_strings = []
                #c+=1
                for key in df.loc[a][4:16].keys():
                    fs.append(float(key.split('F')[1]))
                    fs_strings.append(key)
                start = 4
                stop = 16
                stop2=28
                f_final = []
                for f in fs:
                    if f>600:
                        f_final.append(f*.1)
                    else:
                        f_final.append(f) 

            #Check if the nearby source is brigther than the source of interest by 100nJy in any
            #of the observed filters. If it is, flag the source.
            flags = []
            dfsource = df.loc[ind]
            for fltr in fs_strings:
                for i in leftovers.index:
                    if (leftovers.loc[i][fltr]-dfsource[fltr]) >100:
                        #print('flag')
                        too_close.append(ind)
                        flags.append(i)
    #Plot a black star over any source thrown out because of a nearby source
    close = set(too_close)
    plt.scatter(db1.loc[post_cut].loc[close]['RA'], db1.loc[post_cut].loc[close]['DEC'], marker = '*', color = 'k', s =200,
               label = 'Tossed-Nearby source', zorder = 500)
    #Cut the data 
    throw = db1.loc[post_cut].loc[close]
    good = []
    for ind in db1.loc[post_cut].index:
        if ind not in throw:
            good.append(ind)
    cut_data = db1.loc[good]
    #plot a red star over sources kept after cutting
    plt.scatter(db1.loc[post_cut]['RA'], db1.loc[post_cut]['DEC'], marker = '*', color = 'r', s =200,
               label = 'Kept')
    #Add labels and title
    plt.legend()
    plt.gca().invert_xaxis()
    plt.title(f'Pointing {num} - Data Cuts')
    plt.xlabel('RA(Deg)')
    plt.ylabel('DEC(Deg)');
    return cut_data
def spectra_per_redshift(sources, df, pointing):
    """
    Plots a basic spectra from the specified sources for a given pointing, sorted by redshift
    
    Parameters
    ---
    sources:
    
    df:
    
    pointing: integer,
        number of pointing
    
    """
    #Set figure
    plt.rcParams['figure.figsize'] = (15, 10)
    hits= []
    rsh = []
    ra = []
    dec = []
    kpcs = []
    filter_arrays = []
    filter_arrays_vals = []
    filter_arrays_err = []
    #Get filter values
    k = 0
    try:
        fs = []
        fs_strings = []
        for key in df.loc[k][4:17].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start=4
        stop=17
        stop2 = 30
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)
    except:
        fs = []
        fs_strings = []
        for key in df.loc[k][4:16].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start = 4
        stop = 16
        stop2=28
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)
    for obj in sources:
        #get a DataFrame for just this object
        mk = np.array(df['Object']) == np.array(obj)
        a = df[mk]
        rs = a['PHOTOM_RED_SHIFT'].values
        #kpc = cosmo.kpc_proper_per_arcmin(np.array(rs))
        #Get the filer and redshift values
        f =  np.array(a.keys()[start:stop].values)
        filter_er = np.array(a.keys()[stop:stop2].values)
        mask = (a[f].values[0] > (3*a[filter_er].values[0]))
        filter_arrays_vals.append(a[f].values[0][mask])
        filter_arrays.append(np.array(f_final)[mask])
        rsh.append(rs)
        filter_arrays_err.append(a[filter_er].values[0][mask])
    for i in range(len(rsh)):
        red = rsh[i]
        fvals = filter_arrays_vals[i]
        #create a sorted list to specify correct colors for the barplot
        olist = filter_arrays_vals[i].tolist()
        list_sorted = filter_arrays_vals[i].tolist()
        list_sorted.sort()
        list_index = []
        for x in list_sorted:
            list_index.insert(0,olist.index(x))
        category_colors = plt.cm.pink(np.linspace(0.1, 0.95, len(filter_arrays_vals[i])))[list_index]
        #u=0
        #plot each of the data points. Plot a white block if there was no observed flux
        for j in range(len(f_final)):

            if f_final[j] not in filter_arrays[i]:
                color = 'white'
            else:
                color= category_colors[u]
              #  u+=1
            plt.barh(red, 10, left = f_final[j],  color = color, edgecolor = 'grey', height = 0.05)
            plt.xticks(np.array(f_final)[mask])
            plt.xticks(rotation = 45)
        #set title and axes
        plt.xlim(115, 470)
        plt.ylim(4,9)
        plt.title(f'Sources of Interst Nircam {pointing}')
        plt.xlabel('Filter wavelength $\mu$m')
        plt.ylabel('Redshift')
def reject_outliers(data, max_std):
    return data[abs(data - np.mean(data)) < max_std * np.std(data)]
def get_ew(df, sources):
    filter_widths = {115.0: 0.225 * 1e-6*u.m, 
                150.0: 0.318* 1e-6*u.m,
                105.0: np.nan,
                200: 0.457* 1e-6*u.m,
                277: 0.683* 1e-6*u.m,
                356: 0.781* 1e-6*u.m,
                410: 0.438* 1e-6*u.m,
                444: 1.029* 1e-6*u.m,
                60.6: np.nan,
                81.4: np.nan,
                125: np.nan,
                140: 0.412* 1e-6*u.m,
                160: np.nan}
    # plt.rcParams['figure.figsize'] = (10, 10)
    #sources = cut1['Object']
    hits= []
    rsh = []
    ra = []
    dec = []
    kpcs = []
    filter_arrays = []
    filter_arrays_vals = []
    filter_arrays_err = []
    k = df.index[0]
    try:
        fs = []
        fs_strings = []
        for key in df.loc[k][4:17].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start=4
        stop=17
        stop2 = 30
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)
    except:
        fs = []
        fs_strings = []
       # c+=1
        for key in df.loc[k][4:16].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start = 4
        stop = 16
        stop2=28
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)


    ews_tot =[]
    if len(sources) == 1:
        obj = sources
    else:
        for obj in sources:
           # plt.figure()
           # n+=1
            mk = np.array(df['Object']) == np.array(obj)
            a = df[mk]
            rs = a['PHOTOM_RED_SHIFT'].values
            kpc = cosmo.kpc_proper_per_arcmin(np.array(rs))
            #mask = (a[filters].values[0] > (3*a[filter_er].values[0]))&(a[filters].values[0] >0)
            #if c ==0:
            f =  np.array(a.keys()[start:stop].values)
            filter_er = np.array(a.keys()[stop:stop2].values)
            #else:
              #  filters = np.array(a.keys()[4:17].values)
               # filter_er = np.array(a.keys()[18:30].values)
            mask = (a[f].values[0] > (3*a[filter_er].values[0]))#&(a[filters].values[0] >0)
           # filters = np.array(f_final)[mask]
            #if len(filters)>5:
            filter_arrays_vals.append(a[f].values[0][mask])
            filter_arrays.append(np.array(f_final)[mask])
            rsh.append(rs)
           # a
            filter_arrays_err.append(a[filter_er].values[0][mask])
            max_std = 1
            smooth = reject_outliers(a[f].values[0][mask], 1)
            #cv = np.mean(smooth)
            ews = []
            for inn in range(len(a[f].values[0][mask])):
                z = a['PHOTOM_RED_SHIFT'].values
                ftr = np.array(f_final)[mask][inn]
                fval = a[f].values[0][mask][inn]
                ewrf = (filter_widths[ftr]*(((fval*1e-9*u.Jy)) - (np.mean(smooth)*1e-9*u.Jy))/(np.mean(smooth)*1e-9*u.Jy))
                if ewrf>0:

                    ew = ewrf#/(1+z)
                    ews.append(ew.to(u.AA).value)
                   # print(ewrf>0)
                else:
                    #print(ew)
                    ews.append(np.nan)
            try:
                ews_tot.append(np.nanmax(ews))
            except:
                ews_tot.append(np.nan)
    return ews_tot
def get_ew_red_only(df, sources):
    red = [356.0, 410.0, 444.0]#, 277.0]
    filter_widths = {115.0: 0.225 * 1e-6*u.m, 
                150.0: 0.318* 1e-6*u.m,
                105.0: np.nan,
                200: 0.457* 1e-6*u.m,
                277: 0.683* 1e-6*u.m,
                356: 0.781* 1e-6*u.m,
                410: 0.438* 1e-6*u.m,
                444: 1.029* 1e-6*u.m,
                60.6: np.nan,
                81.4: np.nan,
                125: np.nan,
                140: 0.412* 1e-6*u.m,
                160: np.nan}
    # plt.rcParams['figure.figsize'] = (10, 10)
    #sources = cut1['Object']
    hits= []
    rsh = []
    ra = []
    dec = []
    kpcs = []
    filter_arrays = []
    filter_arrays_vals = []
    filter_arrays_err = []
    k = df.index[0]
    try:
        fs = []
        fs_strings = []
        for key in df.loc[k][4:17].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start=4
        stop=17
        stop2 = 30
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)
    except:
        fs = []
        fs_strings = []
       # c+=1
        for key in df.loc[k][4:16].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start = 4
        stop = 16
        stop2=28
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)


    ews_tot =[]
    if len(sources) == 1:
        obj = sources
    else:
        for obj in sources:
           # plt.figure()
           # n+=1
            mk = np.array(df['Object']) == np.array(obj)
            a = df[mk]
            rs = a['PHOTOM_RED_SHIFT'].values
            kpc = cosmo.kpc_proper_per_arcmin(np.array(rs))
            #mask = (a[filters].values[0] > (3*a[filter_er].values[0]))&(a[filters].values[0] >0)
            #if c ==0:
            f =  np.array(a.keys()[start:stop].values)
            filter_er = np.array(a.keys()[stop:stop2].values)
            #else:
              #  filters = np.array(a.keys()[4:17].values)
               # filter_er = np.array(a.keys()[18:30].values)
            mask = (a[f].values[0] > (3*a[filter_er].values[0]))#&(a[filters].values[0] >0)
           # filters = np.array(f_final)[mask]
            #if len(filters)>5:
            filter_arrays_vals.append(a[f].values[0][mask])
            filter_arrays.append(np.array(f_final)[mask])
            rsh.append(rs)
            filter_arrays_err.append(a[filter_er].values[0][mask])
            max_std = 1
            smooth = reject_outliers(a[f].values[0][mask], 1)
            #cv = np.mean(smooth)
            ews = []
            for inn in range(len(a[f].values[0][mask])):
                z = a['PHOTOM_RED_SHIFT'].values
                ftr = np.array(f_final)[mask][inn]
                fval = a[f].values[0][mask][inn]
                ewrf = (filter_widths[ftr]*(((fval*1e-9*u.Jy)) - (np.mean(smooth)*1e-9*u.Jy))/(np.mean(smooth)*1e-9*u.Jy))
                if ftr in red:
                    if ewrf>0:
                        ew = ewrf#/(1+z)
                        ews.append(ew.to(u.AA).value)
                       # print(ewrf>0)
                    else:
                        #print(ew)
                        ews.append(np.nan)
            try:
                ews_tot.append(np.nanmax(ews))
            except:
                ews_tot.append(np.nan)
    return ews_tot